{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"50\" src=\"https://carbonplan-assets.s3.amazonaws.com/monogram/dark-small.png\" style=\"margin-left:0px;margin-top:20px\"/>\n",
    "\n",
    "# Lionshead Fire Satellite Data Analysis\n",
    "\n",
    "_by Joe Hamman & Jeremy Freeman (CarbonPlan), September 17, 2020_\n",
    "\n",
    "This notebook performs analysis of the\n",
    "[FIRMS Active Fire Dataset](https://firms.modaps.eosdis.nasa.gov/). Below we\n",
    "calculate the fire perimeter for each day and overlay the total burned area to\n",
    "with the impacted ACR260 credited forest offset project.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "Here we take a simple and direct approach to calculated burned area from data\n",
    "provided through the Fire Information for Resource Management System (FIRMS).\n",
    "\n",
    "We begin with the active fire / hotspots shapefiles data (converted to GeoJSON\n",
    "format) that can be\n",
    "[downloaded from the FIRMS website](https://firms.modaps.eosdis.nasa.gov/download/).\n",
    "We include data from the Modis (1km) and VIIRS 375m (Suomi-NPP and NOAA-20)\n",
    "sensors.\n",
    "\n",
    "These data come as point collections that must be merged to form polygons of\n",
    "burned area. Here we apply a buffer on all points of 450 m before merging all\n",
    "points together for each day. The result is a MultiPolygon actively burned area\n",
    "for each day. When comparing the burned area to the ACR project, we further\n",
    "merge all days into a single MultiPolygon.\n",
    "\n",
    "A simplified set of MultiPolygons is saved at the end of the notebook for use in\n",
    "mapping applications.\n",
    "\n",
    "## References\n",
    "\n",
    "- NRT VIIRS 375 m Active Fire product VJ114IMGTDL_NRT. Available on-line\n",
    "  [https://earthdata.nasa.gov/firms]. doi: 10.5067/FIRMS/VIIRS/VJ114IMGT_NRT.002\n",
    "- NRT VIIRS 375 m Active Fire product VNP14IMGT. Available on-line\n",
    "  [https://earthdata.nasa.gov/firms].  \n",
    "  doi:10.5067/FIRMS/VIIRS/VNP14IMGT_NRT.002\n",
    "- MODIS Collection 6 NRT Hotspot / Active Fire Detections MCD14DL. Available\n",
    "  on-line [https://earthdata.nasa.gov/firms]. doi:\n",
    "  10.5067/FIRMS/MODIS/MCD14DL.NRT.006\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "\n",
    "from carbonplan_styles.colors import colors\n",
    "import fsspec\n",
    "import geopandas\n",
    "import hvplot.pandas\n",
    "import intake\n",
    "import pandas as pd\n",
    "import pyproj\n",
    "import shapely\n",
    "from shapely.ops import cascaded_union\n",
    "\n",
    "# plot styles\n",
    "style = \"dark\"\n",
    "c = colors(style)\n",
    "plot_opts = dict(geo=True, tiles=\"CartoDark\", frame_width=800, project=True)\n",
    "\n",
    "# Albers Equal Area Projection - we'll use this as a common projection to work in.\n",
    "working_crs = pyproj.CRS(\n",
    "    projparams=\"+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs\"\n",
    ")\n",
    "\n",
    "# open our data catalog\n",
    "cat = intake.open_catalog(\"./catalog.yaml\")\n",
    "\n",
    "write_to_azure = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Fire data\n",
    "\n",
    "As mentioned above, we've staged the FIRMS data in GeoJSON for ease of use.\n",
    "Here, we load the three data files and concatenate them together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open fire data\n",
    "gdfs = []\n",
    "for sensor in [\"modis\", \"noaa\", \"suomi\"]:\n",
    "    temp = cat.firms(sensor=sensor).read()\n",
    "    print(f\"{sensor}: {len(temp)} records\")\n",
    "    gdfs.append(temp)\n",
    "\n",
    "gdf = pd.concat(gdfs)\n",
    "\n",
    "native_crs = copy.deepcopy(gdf.crs)  # we'll use this again at the end\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Project Polygons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The project geojson is missing its crs, so we're manually specifying it here.\n",
    "project_crs = pyproj.CRS(\n",
    "    'PROJCS[\"NAD_1983_UTM_Zone_10N\",GEOGCS[\"GCS_North_American_1983\",DATUM[\"D_North_American_1983\",SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"false_easting\",500000.0],PARAMETER[\"false_northing\",0.0],PARAMETER[\"central_meridian\",-123.0],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"latitude_of_origin\",0.0],UNIT[\"Meter\",1.0]]'\n",
    ")\n",
    "\n",
    "# Open GeoJSON\n",
    "project = cat.project.read()\n",
    "\n",
    "# Set the CRS then re-project the data to our working CRS\n",
    "project = project.set_crs(project_crs).to_crs(working_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply a buffer to all data points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_to_pixels(points, buf=450):\n",
    "    return [p.buffer(buf) for p in points]\n",
    "\n",
    "\n",
    "gdf = gdf.set_geometry(\n",
    "    points_to_pixels(gdf.geometry.to_crs(working_crs).values), crs=working_crs\n",
    ")\n",
    "gdf[\"date\"] = pd.to_datetime(gdf[\"date\"])\n",
    "\n",
    "display(gdf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all buffered points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_gdf = {}\n",
    "\n",
    "for i, (date, df) in enumerate(gdf.groupby(\"date\")):\n",
    "    merged_gdf[date] = {\n",
    "        \"geometry\": cascaded_union(df.geometry.values),\n",
    "        \"day\": i,\n",
    "    }\n",
    "merged_gdf = geopandas.GeoDataFrame.from_dict(merged_gdf, orient=\"index\")\n",
    "merged_gdf = merged_gdf.set_geometry(\"geometry\").set_crs(working_crs)\n",
    "\n",
    "display(merged_gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerance = 50\n",
    "full_res = merged_gdf.copy()  # keep a copy for the overlay with the project\n",
    "merged_gdf = merged_gdf.set_geometry(\n",
    "    merged_gdf.simplify(tolerance, preserve_topology=False)\n",
    ")\n",
    "merged_gdf[\"date\"] = merged_gdf.index.strftime(\"%Y-%m-%d\")\n",
    "display(merged_gdf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the daily burned area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_gdf.reset_index().to_crs(native_crs).hvplot(\n",
    "    color=\"date\", alpha=0.5, cmap=\"hot\", **plot_opts\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all dates into a single burned area polygon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burned_poly = cascaded_union(full_res.geometry.values)\n",
    "burned_gdf = (\n",
    "    geopandas.GeoDataFrame.from_dict(\n",
    "        {\"row\": {\"geometry\": burned_poly}}, orient=\"index\"\n",
    "    )\n",
    "    .set_geometry(\"geometry\")\n",
    "    .set_crs(working_crs)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlay the burned area and project polygons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burned_project = geopandas.overlay(burned_gdf, project, how=\"intersection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the three polygon sets together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = dict(**plot_opts)\n",
    "del opts[\"tiles\"]\n",
    "\n",
    "plot = (\n",
    "    burned_gdf.to_crs(native_crs).hvplot(\n",
    "        color=c[\"red\"], label=\"fire\", tiles=\"CartoDark\", line_color=None, **opts\n",
    "    )\n",
    "    * project.to_crs(native_crs).hvplot(\n",
    "        color=c[\"text\"], label=\"project\", line_color=None, **opts\n",
    "    )\n",
    "    * burned_project.to_crs(native_crs).hvplot(\n",
    "        color=c[\"green\"], label=\"burned project\", line_color=None, **opts\n",
    "    )\n",
    ")\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add comment confirming the project area matches here.\n",
    "project_area = project.geometry.area.sum()\n",
    "print(\"Project Area: %.2f m2\" % project_area)\n",
    "\n",
    "burned_project_area = burned_project.area.sum()\n",
    "print(\"Burned Project Area: %.2f m2\" % burned_project_area)\n",
    "print(\n",
    "    \"Percent Project Burned: %.2f%%\"\n",
    "    % (burned_project_area / project_area * 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the polygons out to a geojson file for use in the article.\n",
    "if write_to_azure:\n",
    "    # blob file system\n",
    "    from adlfs import AzureBlobFileSystem\n",
    "\n",
    "    fs = AzureBlobFileSystem(\n",
    "        account_name=\"carbonplan\", account_key=os.environ[\"BLOB_ACCOUNT_KEY\"]\n",
    "    )\n",
    "    with fs.open(\n",
    "        \"carbonplan-articles/offset-project-fire/lionshead_fire_polygons.json\",\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        f.write(merged_gdf.to_crs(native_crs).to_json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
